{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things you'll need: \n",
    "1) Jupyter Notebook  \n",
    "2) Chrome Browser  \n",
    "3) Chrome Webdriver  \n",
    "4) Selenium Package  \n",
    "5) Pandas Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Open LinkedIn via Chrome Browser in a Private Tab to filter out targeted jobs being shown to you\n",
    "# Then Search for the jobs you want, in my case I'm going for an entry to mid-level Analyst role so I searched: \n",
    "# \"Data+analyst NOT Software NOT Scientist NOT Senior NOT Sr NOT Engineer\"\n",
    "# This searches for Data Analyst positions and immediately filters out jobs with \"Software\",\"Senior\",\"Sr\",\"Engineer\"\n",
    "# This is so I don't get results for jobs I'm not interested in like a senior role, a job in an unrelated field like Software, or a Data Engineer job\n",
    "url = 'https://www.linkedin.com/jobs/search/?f_E=2%2C3&f_JT=F&f_SB2=3&f_TPR=r2592000&f_WRA=true&geoId=103644278&keywords=data%2Banalyst%20NOT%20software%20NOT%20scientist%20NOT%20senior%20NOT%20Sr%20NOT%20engineer&location=United%20States&locationId=&sortBy=R&position=1&pageNum=0'\n",
    "wd = webdriver.Chrome(\"C:/filepathtochromedriver/chromedriver.exe\")\n",
    "wd.get(url)\n",
    "#With the code above, a Chrome window opens and goes to your search URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code gets the number of jobs available under your search so it can be used by code we'll get to soon\n",
    "no_of_jobs = str(wd.find_element_by_css_selector('h1>span').get_attribute('innerText'))\n",
    "# To be able to treat this as an integer that we can work with, we remove any symbols\n",
    "no_of_jobs = no_of_jobs.replace('+', '')\n",
    "no_of_jobs = no_of_jobs.replace(',','')\n",
    "no_of_jobs = int(no_of_jobs)\n",
    "no_of_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will use the no_of_jobs and scroll all the way down before starting the scrape\n",
    "# LinkedIn sometimes creates a button you have to click to continue scrolling through your results\n",
    "# The path to that button is inserted in the code and is attempted to be clicked every time we scroll down, in case\n",
    "# it decides to appear\n",
    "# Depending on what you searched for, this code might take a few minutes to an hour, go make some tea or coffee or watch \n",
    "# automation do its magic while it scrolls through your results for you!\n",
    "i = 2\n",
    "while i <= int(no_of_jobs/25)+1:\n",
    "    wd.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    i = i + 1\n",
    "    try:\n",
    "         wd.find_element_by_xpath('/html/body/div[1]/div/main/section[2]/button').click()\n",
    "         time.sleep(5)\n",
    "    except:\n",
    "         pass\n",
    "         time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code indexes how many jobs actually appear once you have scrolled through all the results, \n",
    "# and returns the real number of results you receive so it can start creating the report accordingly\n",
    "job_lists = wd.find_element_by_class_name('jobs-search__results-list')\n",
    "jobs = job_lists.find_elements_by_tag_name('li')\n",
    "len(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the real magic starts, this code will go through each job to extract relevant information you'll want to look at\n",
    "# We can go a bit deeper with our scraping, but this provides enough information for now\n",
    "\n",
    "job_id = []\n",
    "job_title = []\n",
    "company_name = []\n",
    "location = []\n",
    "date = []\n",
    "job_link = []\n",
    "\n",
    "for job in jobs:\n",
    "    job_id0 = job.get_attribute('data-id')\n",
    "    job_id.append(job_id0)\n",
    " \n",
    "    job_title0 = job.find_element_by_css_selector('h3').get_attribute('innerText')\n",
    "    job_title.append(job_title0)\n",
    " \n",
    "    company_name0 = job.find_element_by_css_selector('h4').get_attribute('innerText')\n",
    "    company_name.append(company_name0)\n",
    " \n",
    "    location0 = job.find_element_by_css_selector('div>div>span').get_attribute('innerText')\n",
    "    location.append(location0)\n",
    " \n",
    "    date0 = job.find_element_by_css_selector('div>div>time').get_attribute('datetime')\n",
    "    date.append(date0)\n",
    " \n",
    "    job_link0 = job.find_element_by_css_selector('a').get_attribute('href')\n",
    "    job_link.append(job_link0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the data is scraped, we can create a dataframe with pandas, which will be used to generate our report\n",
    "job_data = pd.DataFrame({'ID': job_id,\n",
    "'Date': date,\n",
    "'Company': company_name,\n",
    "'Title': job_title,\n",
    "'Location': location,\n",
    "'Link': job_link\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is to remove irrelevant jobs whose titles might not pertain to us. \n",
    "# If you didn't do any filtering, in the initial job search, you can still do so here.\n",
    "# For example: even though LinkedIn thinks highly of us, if we're just starting in the field \n",
    "# we probably don't want to apply for a Senior position. \n",
    "job_data = job_data[~job_data.Title.str.startswith('Senior')]\n",
    "job_data = job_data[~job_data.Title.str.startswith('Sr')]\n",
    "\n",
    "# We also get some unrelated queries that don't fall in line with our desired outcome\n",
    "# For me I don't want to be a Software Engineer and don't have the advanced statistical knowledge required to\n",
    "# excel as a Data Scientist, so I'll include these filters as well\n",
    "job_data = job_data[~job_data.Title.str.startswith('Software')]\n",
    "job_data = job_data[~job_data.Title.str.contains('Scientist')]\n",
    "\n",
    "# You can also filter out listings based on other fields such as location, company, or date in the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One last thing I do for myself is sort jobs by most recent, If we do this we can be one of the first applicants and/or \n",
    "# look at jobs that are less likely to be filled\n",
    "job_data = job_data.sort_values(by='Date',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick preview to make sure everything looks right\n",
    "job_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we can create our report, which is generated in the same folder as our python/notebook file!\n",
    "job_data.to_excel('LinkedIn Jobs Report.xlsx', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
